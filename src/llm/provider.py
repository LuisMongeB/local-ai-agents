from langchain_ollama import ChatOllama

from src.config import settings


def get_llm() -> ChatOllama:
    """Get configured ChatOllama instance."""
    return ChatOllama(
        model=settings.OLLAMA_MODEL,
        base_url=settings.OLLAMA_BASE_URL,
        temperature=0,
    )
